{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "from sklearn import tree \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import GaussianNB as NB\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Easy Data set: 500 rows and 9241 columns \n",
      "Easy Data set - NB Classifier: Number of mislabels out of 125 points: 14\n",
      "Easy Data set - DT Classifier: Number of mislabels out of 125 points: 22\n"
     ]
    }
   ],
   "source": [
    "# Perform Naiive bayes classification on an easy data set \n",
    "easy = fetch_20newsgroups(subset='train', \n",
    "                          categories=('rec.autos', 'rec.sport.hockey'),\n",
    "                          remove=('headers', 'footers', 'quotes'))\n",
    "tf_vec = CountVectorizer(max_df=500, min_df=0, max_features =10000, ngram_range =(1,1), \n",
    "                         stop_words='english')\n",
    "tf_easy_matrix=tf_vec.fit_transform(easy.data[:500])  #sparse matrix\n",
    "t_easy=np.asarray(easy.target[:500])  \n",
    "full_easy_matrix = pd.DataFrame(tf_easy_matrix.todense(),columns=tf_vec.get_feature_names())\n",
    "print (\"Easy Data set: %d rows and %d columns \" %\n",
    "       (full_easy_matrix.shape[0], full_easy_matrix.shape[1]))\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(full_easy_matrix.as_matrix(),t_easy,random_state=50) \n",
    "clf = NB()\n",
    "y_easy_pred_nb = clf.fit(xtrain, ytrain).predict(xtest)\n",
    "error = (y_easy_pred_nb != ytest).sum()\n",
    "print (\"Easy Data set - NB Classifier: Number of mislabels out of %d points: %d\"\n",
    "       % (xtest.shape[0],error ))\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "y_easy_pred_dt = clf.fit(xtrain, ytrain).predict(xtest)\n",
    "error = (y_easy_pred_dt != ytest).sum()\n",
    "print (\"Easy Data set - DT Classifier: Number of mislabels out of %d points: %d\" % (xtest.shape[0],error ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difficult Data set: 500 rows and 8268 columns \n",
      "Difficult Data set - NB Classifier: Number of mislabels out of 125 points: 33\n",
      "Difficult Data set - DT Classifier: Number of mislabels out of 125 points: 34\n"
     ]
    }
   ],
   "source": [
    "diff = fetch_20newsgroups(subset='train', \n",
    "                          categories=('rec.motorcycles', 'rec.autos'),\n",
    "                          remove=('headers', 'footers', 'quotes'))\n",
    "tf_vec = CountVectorizer(max_df=500, min_df=0, max_features =10000, ngram_range =(1,1), \n",
    "                         stop_words='english')\n",
    "tf_diff_matrix=tf_vec.fit_transform(diff.data[:500])  #sparse matrix\n",
    "t_diff=np.asarray(diff.target[:500])  \n",
    "full_diff_matrix = pd.DataFrame(tf_diff_matrix.todense(),columns=tf_vec.get_feature_names())\n",
    "print (\"Difficult Data set: %d rows and %d columns \" %\n",
    "       (full_diff_matrix.shape[0], full_diff_matrix.shape[1]))\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(full_diff_matrix.as_matrix(),t_diff,random_state=50) \n",
    "clf = NB()\n",
    "y_diff_pred = clf.fit(xtrain, ytrain).predict(xtest)\n",
    "error = (y_diff_pred != ytest).sum()\n",
    "print (\"Difficult Data set - NB Classifier: Number of mislabels out of %d points: %d\"\n",
    "       % (xtest.shape[0],error ))\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "y_diff_pred_dt = clf.fit(xtrain, ytrain).predict(xtest)\n",
    "error = (y_diff_pred_dt != ytest).sum()\n",
    "print (\"Difficult Data set - DT Classifier: Number of mislabels out of %d points: %d\" %\n",
    "       (xtest.shape[0],error ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discussion:\n",
    "# We can see that indeed it's easier to classify the easy data set (as the missclassification \n",
    "# error rate is lower)\n",
    "# We can also see that Naiive Base classifer does better on this data set than a Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difficult Data set - DT with Bagging: Number of mislabels out of 125 points: 30\n"
     ]
    }
   ],
   "source": [
    "# Bagging\n",
    "bagging = BaggingClassifier (tree.DecisionTreeClassifier(), )\n",
    "y_pred = bagging.fit(xtrain, ytrain).predict(xtest)\n",
    "error = (y_pred != ytest).sum()\n",
    "print (\"Difficult Data set - DT with Bagging: Number of mislabels out of %d points: %d\"\n",
    "       % (xtest.shape[0],error ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difficult Data set - NB with AdaBoost: Number of mislabels out of 125 points: 32\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "clf = AdaBoostClassifier(NB(), algorithm=\"SAMME\", n_estimators=300)\n",
    "y_pred = clf.fit(xtrain, ytrain).predict(xtest)\n",
    "error = (y_pred != ytest).sum()\n",
    "print (\"Difficult Data set - NB with AdaBoost: Number of mislabels out of %d points: %d\"\n",
    "       % (xtest.shape[0],error ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difficult Data set - RF: Number of mislabels out of 125 points: 35\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=None,random_state=10, max_features='auto')\n",
    "y_pred = clf.fit(xtrain, ytrain).predict(xtest)\n",
    "error = (y_pred != ytest).sum()\n",
    "print (\"Difficult Data set - RF: Number of mislabels out of %d points: %d\"\n",
    "       % (xtest.shape[0],error ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can see that all the ensembles improve the classification, but to the same degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: data has 2323 rows and 29847 columns \n"
     ]
    }
   ],
   "source": [
    "sample = fetch_20newsgroups(subset='train',\n",
    "                            categories=('comp.graphics', 'rec.autos', 'talk.politics.guns',\n",
    "                                       'soc.religion.christian'),\n",
    "                            remove=('headers', 'footers', 'quotes'))\n",
    "tf_sample_vec = CountVectorizer (max_df=500, min_df=0, max_features=30000, ngram_range =(1,1),\n",
    "                                 stop_words='english')\n",
    "tf_sample_matrix=tf_sample_vec.fit_transform(sample.data)  #sparse matrix\n",
    "print (\"Sample: data has %d rows and %d columns \"\n",
    "       % (tf_sample_matrix.shape[0], tf_sample_matrix.shape[1]))\n",
    "full_sample_matrix = pd.DataFrame(tf_sample_matrix.todense(),\n",
    "                                  columns=tf_sample_vec.get_feature_names())\n",
    "t_sample=np.asarray(sample.target)   \n",
    "xtrain, xtest, ytrain, ytest = train_test_split(full_sample_matrix.as_matrix(),\n",
    "                                                t_sample,random_state=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-vs-All NB: Number of mislabels out of 581 points in the test test: 125\n",
      "All-vs-All NB: Number of mislabels out of 581 points in the test test: 71\n"
     ]
    }
   ],
   "source": [
    "clf = NB() # NB\n",
    "\n",
    "y_pred = OneVsRestClassifier(clf).fit(xtrain, ytrain).predict(xtest)\n",
    "error = (y_pred != ytest).sum()\n",
    "print (\"One-vs-All NB: Number of mislabels out of %d points in the test test: %d\"\n",
    "       % (xtest.shape[0],error ))\n",
    "\n",
    "y_pred = OneVsOneClassifier(clf).fit(xtrain, ytrain).predict(xtest)\n",
    "error = (y_pred != ytest).sum()\n",
    "print (\"All-vs-All NB: Number of mislabels out of %d points in the test test: %d\"\n",
    "       % (xtest.shape[0],error ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-vs-All DT: Number of mislabels out of 581 points in the test test: 119\n",
      "All-vs-All DT: Number of mislabels out of 581 points in the test test: 121\n"
     ]
    }
   ],
   "source": [
    "clf =  tree.DecisionTreeClassifier() # DT\n",
    "\n",
    "y_pred = OneVsRestClassifier(clf).fit(xtrain, ytrain).predict(xtest)\n",
    "error = (y_pred != ytest).sum()\n",
    "print (\"One-vs-All DT: Number of mislabels out of %d points in the test test: %d\"\n",
    "       % (xtest.shape[0],error ))\n",
    "\n",
    "y_pred = OneVsOneClassifier(clf).fit(xtrain, ytrain).predict(xtest)\n",
    "error = (y_pred != ytest).sum()\n",
    "print (\"All-vs-All DT: Number of mislabels out of %d points in the test test: %d\"\n",
    "       % (xtest.shape[0],error ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-vs-All LinearSVC: Number of mislabels out of 581 points in the test test: 92\n",
      "All-vs-All LinearSVC: Number of mislabels out of 581 points in the test test: 100\n"
     ]
    }
   ],
   "source": [
    "clf= LinearSVC(random_state=10) # LinearSVC\n",
    "\n",
    "y_pred = OneVsRestClassifier(clf).fit(xtrain, ytrain).predict(xtest)\n",
    "error = (y_pred != ytest).sum()\n",
    "print (\"One-vs-All LinearSVC: Number of mislabels out of %d points in the test test: %d\"\n",
    "       % (xtest.shape[0],error ))\n",
    "\n",
    "y_pred = OneVsOneClassifier(clf).fit(xtrain, ytrain).predict(xtest)\n",
    "error = (y_pred != ytest).sum()\n",
    "print (\"All-vs-All LinearSVC: Number of mislabels out of %d points in the test test: %d\"\n",
    "       % (xtest.shape[0],error ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ranking from best performer to worst perfomer:\n",
    "# AvA NB > OvA LinearSVC > AvA LinearSVC > OvA DT > AvA DT > OvA NB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given (x1,y1)….(xn,yn) and initial weights of data points wi = 1/n, i=1…n\n",
    "# Weights are updated according to the formula: wi = wi*exp⁡(cm.1(y≠fm(x)), i=1…n  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
